# AUDIO-CLASSIFICATION
Audio classification is a crucial task in machine learning, with applications in environmental sound recognition, speech processing, and security systems. In this study, I leverage the UrbanSound8K dataset, which comprises urban sound recordings across ten classes such as dog barks, car horns, and sirens. We preprocess the audio data using Librosa, extracting key features like Mel-frequency cepstral coefficients (MFCCs), spectrograms, and waveform representations.
I implement and compare multiple machine learning models, including Support Vector Machines (SVM), Random Forest, and Neural Networks, to classify audio samples. Experimental results demonstrate the effectiveness of deep learning-based approaches, particularly convolutional neural networks (CNNs), in achieving high classification accuracy. 
This research provides insights into optimizing audio feature extraction and model selection for real-world sound classification tasks.
I am in process to complete this project, completing Exploratory detailed analysis (EDA).
